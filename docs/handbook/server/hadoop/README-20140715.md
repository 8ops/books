


================================================================================
整合搭建 hdfs/zookeeper/bookkeeper/hbase
================================================================================

一，基础环境准备

ps: 需要在每一台机器上做此操作

先在每台机器上操作

1，创建用户并埋key

useradd -m -G sshuser hadoop

mkdir /home/hadoop/.ssh
chmod 700 /home/hadoop/.ssh

vim /home/hadoop/.ssh/id_dsa
-----BEGIN DSA PRIVATE KEY-----
MIIBvAIBAAKBgQDWWwKgd8fbTJJvxqHghBMRac6kZHbvJpaBB+yY8cqzHukNOVN6
gCtN5gXvGo1GGBP7Mnz/4DwcgyCSwjBWiZrCgtjm3gwj69tuNMkgEatCteUsYplv
LCrL2BDUvAGIj+kxafvCwdZcuEm1Ytgks5VRpE/yBF2lp/8ARWr+EDnBQwIVALmu
4+axCWYHw8cVtEMJhcV9EaQ7AoGBAMncFL+ZXn7KWe9tiCrKqjTXomPSr+0+5YVk
E1yd/YUgoytkQheQ0oCBLgzmt8dCindWhMPQs4A+FAO3AgNpHfPIDVr9MLPcAhtG
HQy6kx5CVAYfK6A/cJkBpgUYczWOniealJWdqN8EVza60x8ekLkCuhi0OjNJIiQj
CPE1GlXxAoGBAJbA969PnhmOm9T3h2aUhNDXuA3yyc9Gg3dpySKelGTsVsuNip86
gx7z3Yder4R1jgiQFTdFLrd1e6P4V5WJ4eG3Ibxwbu95yceSWCLpKckgBNjnF/6L
5vCwGKp3wjXrE1P856gfFLNvbYWN/hkV6vbgPitGzTK0fXunV4esvtGqAhQ5G1Sg
To2sKaGMpzmz0DfktK1QcA==
-----END DSA PRIVATE KEY-----

vim /home/hadoop/.ssh/authorized_keys
ssh-dss AAAAB3NzaC1kc3MAAACBANZbAqB3x9tMkm/GoeCEExFpzqRkdu8mloEH7JjxyrMe6Q05U3qAK03mBe8ajUYYE/syfP/gPByDIJLCMFaJmsKC2ObeDCPr2240ySARq0K15SximW8sKsvYENS8AYiP6TFp+8LB1ly4SbVi2CSzlVGkT/IEXaWn/wBFav4QOcFDAAAAFQC5ruPmsQlmB8PHFbRDCYXFfRGkOwAAAIEAydwUv5lefspZ722IKsqqNNeiY9Kv7T7lhWQTXJ39hSCjK2RCF5DSgIEuDOa3x0KKd1aEw9CzgD4UA7cCA2kd88gNWv0ws9wCG0YdDLqTHkJUBh8roD9wmQGmBRhzNY6eJ5qUlZ2o3wRXNrrTHx6QuQK6GLQ6M0kiJCMI8TUaVfEAAACBAJbA969PnhmOm9T3h2aUhNDXuA3yyc9Gg3dpySKelGTsVsuNip86gx7z3Yder4R1jgiQFTdFLrd1e6P4V5WJ4eG3Ibxwbu95yceSWCLpKckgBNjnF/6L5vCwGKp3wjXrE1P856gfFLNvbYWN/hkV6vbgPitGzTK0fXunV4esvtGq hadoop@master.hadoop.youja.cn

chown -R hadoop.hadoop /home/hadoop/.ssh
chmod 600 /home/hadoop/.ssh/id_dsa
chmod 600 /home/hadoop/.ssh/authorized_keys
ls -l /home/hadoop/.ssh

2，创建目录并授权给 hadoop

mkdir -p /usr/local/hadoop /data/hadoop
chown -R hadoop.hadoop /usr/local/src /usr/local/hadoop /data/hadoop 

3,环境配置

vim /etc/profile.d/hadoop-env.sh


export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

# env jdk1.6
export JAVA_HOME=/usr/local/hadoop/jdk1.6.0_27
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:%JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH

# env hadoop
export HADOOP_HOME=/usr/local/hadoop/hadoop-2.2.0
export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH
export HADOOP_HOME_WARN_SUPPRESS=1

# env zookeeper
export ZOOKEEPER_HOME=/usr/local/hadoop/zookeeper-3.4.6
export BOOKKEEPER_HOME=/usr/local/hadoop/bookkeeper-server-4.2.3
export PATH=$ZOOKEEPER_HOME/bin:$BOOKKEEPER_HOME/bin:$PATH

# env hbase
export HBASE_HOME=/usr/local/hadoop/hbase-0.96.2-hadoop2
export PATH=$HBASE_HOME/bin:$PATH

4，DNS 解析

192.168.1.225       namenode.hadoop.youja.cn             zk01.hadoop.youja.cn 
192.168.1.226       secondarynamenode.hadoop.youja.cn    zk02.hadoop.youja.cn
192.168.1.227       datanode01.hadoop.youja.cn           zk03.hadoop.youja.cn
192.168.1.228       datanode02.hadoop.youja.cn           zk04.hadoop.youja.cn
192.168.1.229       datanode03.hadoop.youja.cn           zk05.hadoop.youja.cn

5，生成~/known_hosts信息
su hadoop 

for host in namenode.hadoop.youja.cn secondarynamenode.hadoop.youja.cn datanode01.hadoop.youja.cn datanode02.hadoop.youja.cn datanode03.hadoop.youja.cn
do
    echo "====> $host"
    ssh -p 50022 hadoop@$host "date"
done

for i in {1..5}
do
    host=zk0$i.hadoop.youja.cn
    echo "====> $host"
    ssh -p 50022 hadoop@$host "date"
done

6，更改每台机器 hostname
vim /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=namenode.hadoop.youja.cn

vim /etc/hosts

...

127.0.0.1  namenode.hadoop.youja.cn

7，查看状态
watch jps


二，软件安装　

ps: 只需要在一台机器上安装，然后同步至其它机器。在一台机器上同步配置至其它机器并启动和停止

su hadoop

1，对应版本
jdk1.6.0_27
hadoop-2.2.0
zookeeper-3.4.6
bookkeeper-server-4.2.3
hbase-0.96.2-hadoop2

2，下载并安装

cd /usr/local/src
wget http://file.uplus.youja.cn/maven%2beclipse/jdk-6u27-linux-x64.bin
wget http://file.uplus.youja.cn/hadoop/hadoop-centos6.4-x64-2.2.0.tar.gz
wget http://file.uplus.youja.cn/hadoop/zookeeper/zookeeper-3.4.6.tar.gz
wget http://file.uplus.youja.cn/hadoop/zookeeper/bookkeeper-server-4.2.3-bin.tar.gz
wget http://file.uplus.youja.cn/hadoop/hbase/hbase-0.96.2-hadoop2-bin.tar.gz

chmod +x jdk-6u27-linux-x64.bin
./jdk-6u27-linux-x64.bin
tar xvzf hadoop-centos6.4-x64-2.2.0.tar.gz
tar xvzf zookeeper-3.4.6.tar.gz
tar xvzf bookkeeper-server-4.2.3-bin.tar.gz
tar xvzf hbase-0.96.2-hadoop2-bin.tar.gz

mv jdk1.6.0_27 hadoop-2.2.0 zookeeper-3.4.6 bookkeeper-server-4.2.3  hbase-0.96.2-hadoop2 /usr/local/hadoop/

3，修改 hdfs 配置

vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/core-site.xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://namenode.hadoop.youja.cn:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/data/hadoop/hdfs/temp</value>
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>/data/hadoop/hdfs/name,/data/hadoop/hdfs/2ndname</value> 
  </property>
  <property>
    <name>fs.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>fs.checkpoint.size</name>
    <value>67108864</value>
  </property>
</configuration>


vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/hdfs-site.xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.name.dir</name>
    <value>/data/hadoop/hdfs/name,/data/hadoop/hdfs/2ndname</value>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/data/hadoop/hdfs/data</value>
  </property>
  <property>
    <name>dfs.secondary.http.address</name>
    <value>secondarynamenode.hadoop.youja.cn:50090</value>
  </property>
  <property>
    <name>dfs.http.address</name>
    <value>namenode.hadoop.youja.cn:50070</value>
  </property>
</configuration>


vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/mapred-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>hdfs://namenode.hadoop.youja.cn:9001</value>
  </property>
</configuration>


vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/masters
namenode.hadoop.youja.cn

vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/slaves
datanode01.hadoop.youja.cn
datanode02.hadoop.youja.cn
datanode03.hadoop.youja.cn

vim /usr/local/hadoop/hadoop-2.2.0/etc/hadoop/hadoop-env.sh

...

# Extra ssh options.  Empty by default.
export HADOOP_SSH_OPTS="-p 50022 -o ConnectTimeout=1 -o SendEnv=HADOOP_CONF_DIR"

# map reduce slow
export HADOOP_HEAPSIZE=4000


4，修改 zookeeper 配置

vim /usr/local/hadoop/zookeeper-3.4.6/conf/zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/hadoop/zookeeper/data
clientPort=2181

server.1=zk01.hadoop.youja.cn:2888:3888
server.2=zk02.hadoop.youja.cn:2888:3888
server.3=zk03.hadoop.youja.cn:2888:3888
server.4=zk04.hadoop.youja.cn:2888:3888
server.5=zk05.hadoop.youja.cn:2888:3888

dataLogDir=/data/hadoop/zookeeper/log

5，修改 bookkeeper 配置

vim /usr/local/hadoop/bookkeeper-server-4.2.3/conf/bk_server.conf 
#!/bin/sh

bookiePort=3181

journalDirectory=/data/hadoop/zookeeper/bookkeeper/bk-txn
ledgerDirectories=/data/hadoop/zookeeper/bookkeeper/bk-data
zkLedgersRootPath=/ledgers
flushInterval=100
zkServers=zk01.hadoop.youja.cn:2181,zk02.hadoop.youja.cn:2181,zk03.hadoop.youja.cn:2181,zk04.hadoop.youja.cn:2181,zk05.hadoop.youja.cn
zkTimeout=10000
serverTcpNoDelay=true

6，修改 hbase 配置

vim /usr/local/hadoop/hbase-0.96.2-hadoop2/conf/hbase-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://namenode.hadoop.youja.cn:9000/hbase</value>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  
</configuration>

vim /usr/local/hadoop/hbase-0.96.2-hadoop2/conf/regionservers
datanode01.hadoop.youja.cn 
datanode02.hadoop.youja.cn 
datanode03.hadoop.youja.cn

vim /usr/local/hadoop/hbase-0.96.2-hadoop2/conf/hbase-env.sh

...

# Extra ssh options.  Empty by default.
export HBASE_SSH_OPTS="-p 50022 -o ConnectTimeout=1 -o SendEnv=HADOOP_CONF_DIR"


rsync -rltv /usr/local/hadoop/hbase-0.96.2-hadoop2/lib/ /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/
rm -f /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.6.4.jar

cd /usr/local/hadoop/hbase-0.96.2-hadoop2/conf
ln -s ../../hadoop-2.2.0/etc/hadoop/hdfs-site.xml ./

7，同步程序和目录结构至其它机器

rm -f /usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-runtime-5.5.23.jar
rm -f /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar
rm -f /usr/local/hadoop/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar
rm -f /usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-compiler-5.5.23.jar
rm -f /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar
wget -O /usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-runtime-5.5.12.jar http://file.uplus.youja.cn/hadoop/jasper-runtime-5.5.12.jar
wget -O /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.12.jar http://file.uplus.youja.cn/hadoop/jasper-runtime-5.5.12.jar
wget -O /usr/local/hadoop/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.12.jar http://file.uplus.youja.cn/hadoop/jasper-runtime-5.5.12.jar
wget -O /usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-compiler-5.5.12.jar http://file.uplus.youja.cn/hadoop/jasper-compiler-5.5.12.jar
wget -O /usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.12.jar http://file.uplus.youja.cn/hadoop/jasper-compiler-5.5.12.jar

for i in {1..5}
do
    host=zk0$i.hadoop.youja.cn
    echo "====> $host"
    ssh -p 50022 hadoop@$host "mkdir -p /data/hadoop/hdfs/{name,2ndname,data,temp};mkdir -p /data/hadoop/zookeeper/{data,log,bookkeeper}"
    rsync -rtlv --delete -e "ssh -p 50022" --exclude "*/logs" /usr/local/hadoop/ hadoop@$host:/usr/local/hadoop/
    #rsync -rtlv -e "ssh -p 50022" --exclude "*/logs" /usr/local/hadoop/ hadoop@$host:/usr/local/hadoop/
done

配置过程中修复

for i in {1..5}
do
    host=zk0$i.hadoop.youja.cn
    echo "====> $host"
    #ssh -p 50022 hadoop@$host "rm -rf /usr/local/hadoop/*/logs/*;rm -rf /tmp/Jetty*;rm -f /tmp/*.pid;rm -rf /tmp/*hadoop;rm -f ~/nohup.out  ~/zookeeper.out"
    
    ssh -p 50022 hadoop@$host "rm -rf /usr/local/hadoop/*/logs/*;"
    #ssh -p 50022 hadoop@$host "rm -rf /usr/local/hadoop/*/logs/*;rm -rf /data/hadoop/*;"
    #rsync -rtlv -e "ssh -p 50022" --exclude "*/logs" /usr/local/hadoop/ hadoop@$host:/usr/local/hadoop/
    
    #ssh -p 50022 hadoop@$host "tree /data"
    #ssh -p 50022 hadoop@$host "netstat -nutlp"
done


三，启动

1，hdfs 

格式化

hadoop namenode -format

启动／停止

start-all.sh
stop-all.sh

2，zookeeper

for i in {1..5}
do
    host=zk0$i.hadoop.youja.cn
    echo "====> $host"
    #ssh -p 50022 hadoop@$host "/usr/local/hadoop/zookeeper-3.4.6/bin/zkServer.sh stop /usr/local/hadoop/zookeeper-3.4.6/conf/zoo.cfg"
    #ssh -p 50022 hadoop@$host "rm -f /data/hadoop/zookeeper/data/zookeeper_server.pid"
    
    ssh -p 50022 hadoop@$host "echo \"$i\" >  /data/hadoop/zookeeper/data/myid"
    ssh -p 50022 hadoop@$host "/usr/local/hadoop/zookeeper-3.4.6/bin/zkServer.sh start /usr/local/hadoop/zookeeper-3.4.6/conf/zoo.cfg"
    
    ssh -p 50022 hadoop@$host "tree /data/hadoop/zookeeper"
done

3，bookkeeper

zkCli.sh -server zk01.hadoop.youja.cn
create /ledgers bookkeeper
create /ledgers/available bookkeeper


for i in {1..5}
do
    host=zk0$i.hadoop.youja.cn
    echo "====> $host"
    #ssh -p 50022 hadoop@$host "bookkeeper-daemon.sh start bookie"
    ssh -p 50022 hadoop@$host "bookkeeper-daemon.sh stop bookie"
done

4，hbase

start-hbase.sh
stop-hbase.sh


四，使用测试

1，查看节点信息

tree /data/hadoop
/data/hadoop/
├── hdfs
│   ├── data
│   ├── name
│   │   ├── current
│   │   │   ├── edits_0000000000000000001-0000000000000000002
│   │   │   ├── edits_inprogress_0000000000000000003
│   │   │   ├── fsimage_0000000000000000000
│   │   │   ├── fsimage_0000000000000000000.md5
│   │   │   ├── fsimage_0000000000000000002
│   │   │   ├── fsimage_0000000000000000002.md5
│   │   │   ├── seen_txid
│   │   │   └── VERSION
│   │   └── in_use.lock
│   └── temp
└── zookeeper
    ├── bookkeeper
    │   ├── bk-data
    │   │   └── current
    │   │       ├── 0.log
    │   │       ├── 1.log
    │   │       ├── lastId
    │   │       └── VERSION
    │   └── bk-txn
    │       └── current
    │           ├── 147340fd3d6.txn
    │           ├── 147340fd3d7.txn
    │           └── VERSION
    ├── data
    │   ├── myid
    │   ├── version-2
    │   │   ├── acceptedEpoch
    │   │   ├── currentEpoch
    │   │   └── snapshot.0
    │   └── zookeeper_server.pid
    └── log
        └── version-2
            └── log.100000001

15 directories, 22 files


hadoop fs -mkdir /test
hadoop fs -put /etc/service /test/
hadoop fs -copyFromLocal /etc/ssh/ssh_config /test/txt002.txt

hadoop dfsadmin -report

http://namenode.hadoop.youja.cn:50070/dfshealth.jsp

zkCli.sh -server zk01.hadoop.youja.cn

hbase shell
create 'test','cf'
put 'test','row1','cf:a','value1'
put 'test','row2','cf:b','value2'
put 'test','row3','cf:c','value3'
scan 'test'
get 'test','row1'
disable 'test'

http://namenode.hadoop.youja.cn:60010

hbase zkcli -server namenode.hadoop.youja.cn:2181

--------------------------------------------------------------------------------
问题集锦

1，启动与停止，重启的顺序

启动　hdfs --> zookeeper --> bookkeeper --> hbase

停止　hbase --> hdfs --> zookeeper

重启　停止 --> 启动

2，jar 版本替换（遇到namenode datanode 启不来，报jar notsuchfileerror is_security_enabled）

/usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-runtime-5.5.23.jar
/usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar
/usr/local/hadoop/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar

/usr/local/hadoop/hbase-0.96.2-hadoop2/lib/jasper-compiler-5.5.23.jar
/usr/local/hadoop/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar



替换为
jasper-compiler-5.5.12.jar
jasper-runtime-5.5.12.jar




















================================================================================
hdfs 环境搭建整理
================================================================================

Hadoop 的集群搭建

一，编译 x64 位 hadoop （步骤略）

http://file.uplus.youja.cn/hadoop/hadoop-centos6.4-x64-2.2.0.tar.gz
http://file.uplus.youja.cn/hadoop/hadoop-ubuntu12.04-x64-2.2.0.tar.gz

二，搭建环境

192.168.1.219       secondary.hadoop.youja.cn z01.zookeeper.youja.cn 
192.168.1.220       master.hadoop.youja.cn    z02.zookeeper.youja.cn
192.168.1.221       slave01.hadoop.youja.cn   z03.zookeeper.youja.cn
192.168.1.222       slave02.hadoop.youja.cn   z04.zookeeper.youja.cn
192.168.1.223       slave03.hadoop.youja.cn   z05.zookeeper.youja.cn

关闭 iptables ip6tables selinux
调整 ulimit
设备login: echo "session required /lib64/security/pam_limits.so" >> /etc/pam.d/login
调整jvm

1，环境配置

vim /etc/profile.d/hadoop.sh 
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

# env jdk1.7
#export JAVA_HOME=/usr/local/jdk1.6.0_27
export JAVA_HOME=/usr/local/jdk1.7.0_60
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:%JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH

# env hadoop
export HADOOP_HOME=/usr/local/hadoop-2.2.0
export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH
export HADOOP_HOME_WARN_SUPPRESS=1

2，埋key

useradd -m -G sshuser hadoop

mkdir /home/hadoop/.ssh
chmod 700 /home/hadoop/.ssh

vim /home/hadoop/.ssh/id_dsa
-----BEGIN DSA PRIVATE KEY-----
MIIBvAIBAAKBgQDWWwKgd8fbTJJvxqHghBMRac6kZHbvJpaBB+yY8cqzHukNOVN6
gCtN5gXvGo1GGBP7Mnz/4DwcgyCSwjBWiZrCgtjm3gwj69tuNMkgEatCteUsYplv
LCrL2BDUvAGIj+kxafvCwdZcuEm1Ytgks5VRpE/yBF2lp/8ARWr+EDnBQwIVALmu
4+axCWYHw8cVtEMJhcV9EaQ7AoGBAMncFL+ZXn7KWe9tiCrKqjTXomPSr+0+5YVk
E1yd/YUgoytkQheQ0oCBLgzmt8dCindWhMPQs4A+FAO3AgNpHfPIDVr9MLPcAhtG
HQy6kx5CVAYfK6A/cJkBpgUYczWOniealJWdqN8EVza60x8ekLkCuhi0OjNJIiQj
CPE1GlXxAoGBAJbA969PnhmOm9T3h2aUhNDXuA3yyc9Gg3dpySKelGTsVsuNip86
gx7z3Yder4R1jgiQFTdFLrd1e6P4V5WJ4eG3Ibxwbu95yceSWCLpKckgBNjnF/6L
5vCwGKp3wjXrE1P856gfFLNvbYWN/hkV6vbgPitGzTK0fXunV4esvtGqAhQ5G1Sg
To2sKaGMpzmz0DfktK1QcA==
-----END DSA PRIVATE KEY-----

vim /home/hadoop/.ssh/authorized_keys
ssh-dss AAAAB3NzaC1kc3MAAACBANZbAqB3x9tMkm/GoeCEExFpzqRkdu8mloEH7JjxyrMe6Q05U3qAK03mBe8ajUYYE/syfP/gPByDIJLCMFaJmsKC2ObeDCPr2240ySARq0K15SximW8sKsvYENS8AYiP6TFp+8LB1ly4SbVi2CSzlVGkT/IEXaWn/wBFav4QOcFDAAAAFQC5ruPmsQlmB8PHFbRDCYXFfRGkOwAAAIEAydwUv5lefspZ722IKsqqNNeiY9Kv7T7lhWQTXJ39hSCjK2RCF5DSgIEuDOa3x0KKd1aEw9CzgD4UA7cCA2kd88gNWv0ws9wCG0YdDLqTHkJUBh8roD9wmQGmBRhzNY6eJ5qUlZ2o3wRXNrrTHx6QuQK6GLQ6M0kiJCMI8TUaVfEAAACBAJbA969PnhmOm9T3h2aUhNDXuA3yyc9Gg3dpySKelGTsVsuNip86gx7z3Yder4R1jgiQFTdFLrd1e6P4V5WJ4eG3Ibxwbu95yceSWCLpKckgBNjnF/6L5vCwGKp3wjXrE1P856gfFLNvbYWN/hkV6vbgPitGzTK0fXunV4esvtGq hadoop@master.hadoop.youja.cn

chown -R hadoop.hadoop /home/hadoop/.ssh
chmod 600 /home/hadoop/.ssh/id_dsa
chmod 600 /home/hadoop/.ssh/authorized_keys
ls -l /home/hadoop/.ssh
-rw-r--r-- 1 hadoop hadoop 619 7月   6 16:54 authorized_keys
-rw------- 1 hadoop hadoop 672 7月   6 16:54 id_dsa

测试通过key登录其它机器
su hadoop
for host in secondary.hadoop.youja.cn master.hadoop.youja.cn slave01.hadoop.youja.cn slave02.hadoop.youja.cn slave03.hadoop.youja.cn
do
    ssh -p 50022 $host date
done


3，创建目录

rm -rf /data/hdfs/*
mkdir -p /data/hdfs/{name,data,tmp}
chown -R hadoop.hadoop /data/hdfs

4，参数配置
vim /usr/local/hadoop-2.2.0/etc/hadoop/core-site.xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://master.hadoop.youja.cn:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/data/hdfs/tmp</value>
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>/data/hdfs/name</value> 
  </property>
  <property>
    <name>fs.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>fs.checkpoint.size</name>
    <value>67108864</value>
  </property>

</configuration>


vim /usr/local/hadoop-2.2.0/etc/hadoop/hdfs-site.xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.name.dir</name>
    <value>/data/hdfs/name</value>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/data/hdfs/data</value>
  </property>
  <property>
    <name>dfs.secondary.http.address</name>
    <value>secondary.hadoop.youja.cn:50090</value>
  </property>
  <property>
    <name>dfs.http.address</name>
    <value>master.hadoop.youja.cn:50070</value>
  </property>
</configuration>


vim /usr/local/hadoop-2.2.0/etc/hadoop/mapred-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>hdfs://master.hadoop.youja.cn:9001</value>
  </property>
</configuration>



vim /usr/local/hadoop-2.2.0/etc/hadoop/masters
master.hadoop.youja.cn

vim /usr/local/hadoop-2.2.0/etc/hadoop/slaves
slave01.hadoop.youja.cn
slave02.hadoop.youja.cn
slave03.hadoop.youja.cn

vim /usr/local/hadoop-2.2.0/etc/hadoop/hadoop-env.sh
# Extra ssh options.  Empty by default.
export HADOOP_SSH_OPTS="-p 50022 -o ConnectTimeout=1 -o SendEnv=HADOOP_CONF_DIR"

# map reduce slow
export HADOOP_HEAPSIZE=4000

将配置文件同步到其它机器，除 masters

更改配置后会动态感知，不用重新启动

chown -R hadoop.hadoop /usr/local/hadoop-2.2.0

su hadoop
for host in secondary.hadoop.youja.cn slave01.hadoop.youja.cn slave02.hadoop.youja.cn slave03.hadoop.youja.cn
do
    rsync -rtlv --exclude=/usr/local/hadoop-2.2.0/logs -e "ssh -p 50022" /usr/local/hadoop-2.2.0/ hadoop@$host:/usr/local/hadoop-2.2.0/
done

在slave机器上
rm -f /usr/local/hadoop-2.2.0/etc/hadoop/masters

5，初始化和启动
在master上，格式化
hadoop namenode -format

查看目录变化
tree /data/hdfs

启动／停止
start-all.sh
stop-all.sh

查看hadoop启动进程
jps

查看hadoop运行状态
hadoop dfsadmin -report

浏览器查看hadoop运行状态
http://master.hadoop.youja.cn:50070/dfshealth.jsp


hadoop fs -mkdir /test
hadoop fs -put /etc/service /test/
hadoop fs -copyFromLocal /etc/ssh/ssh_config /test/txt002.txt

================================================================================
eclipse 配置
================================================================================

http://file.uplus.youja.cn/hadoop/hadoop-eclipse-plugin-2.2.0.jar ==> eclipse/plugins

----> /usr/local/hadoop-2.2.0

windows ==> show view / Map/Reduce

Run configuration args ==> hdfs://master.hadoop.youja.cn:9000/test/input hdfs://master.hadoop.youja.cn:9000/test/output

================================================================================
zookeeper 环境搭建整理
================================================================================
   
一，环境说明

192.168.1.219        z01.zookeeper.youja.cn 
192.168.1.220        z02.zookeeper.youja.cn
192.168.1.221        z03.zookeeper.youja.cn
192.168.1.222        z04.zookeeper.youja.cn
192.168.1.223        z05.zookeeper.youja.cn

二，搭建
http://zookeeper.apache.org

cd /usr/local/src
wget http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
wget http://mirrors.hust.edu.cn/apache/zookeeper/bookkeeper/bookkeeper-4.2.3/bookkeeper-server-4.2.3-bin.tar.gz

tar xvzf zookeeper-3.4.6.tar.gz -C /usr/local
tar xvzf bookkeeper-server-4.2.3.tar.gz -C /usr/local

三，环境配置

vim /etc/profile.d/hadoop.sh

# env jdk1.6
export JAVA_HOME=/usr/local/jdk1.6.0_27
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:%JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH

# env zookeeper and bookkeeper
export ZOOKEEPER_HOME=/usr/local/zookeeper-3.4.6
export BOOKKEEPER_HOME=/usr/local/bookkeeper-server-4.2.3
export PATH=$ZOOKEEPER_HOME/bin:$BOOKKEEPER_HOME/bin:$PATH

dns 解析
机器间埋key 通过hadoop用户可以相互访问

四，配置准备

vim /usr/local/zookeeper-3.4.6/conf/zoo.cfg

tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/zookeeper/data
clientPort=2181

server.1=z01.zookeeper.youja.cn:2888:3888
server.2=z02.zookeeper.youja.cn:2888:3888
server.3=z03.zookeeper.youja.cn:2888:3888
server.4=z04.zookeeper.youja.cn:2888:3888
server.5=z05.zookeeper.youja.cn:2888:3888

dataLogDir=/data/zookeeper/log

五，同步配置至其它机器并启动

mkdir -p /data
chown -R hadoop.hadoop /data
chown chown -R hadoop.hadoop /usr/local/jdk1.6.0_27 /usr/local/zookeeper-3.4.6 /usr/local/bookkeeper-server-4.2.3 

su hadoop 
mkdir -p /data/zookeeper/{data,log,bookkeeper}
echo "1" >  /data/zookeeper/data/myid
/usr/local/zookeeper-3.4.6/bin/zkServer.sh start /usr/local/zookeeper-3.4.6/conf/zoo.cfg
tree /data/zookeeper

六，注意
1，启动不成功时 rm -f /data/zookeeper/data/zookeeper_server.pid



================================================================================
bookkeeper 使用
================================================================================

一，基于zookeeper的环境

zkCli.sh -server z01.zookeeper.youja.cn
create /ledgers bookkeeper

二，配置bookkeeper
vim /usr/local/bookkeeper-server-4.2.3/conf/bk_server.conf 
#!/bin/sh

bookiePort=3181

journalDirectory=/data/zookeeper/bookkeeper/bk-txn
ledgerDirectories=/data/zookeeper/bookkeeper/bk-data
zkLedgersRootPath=/ledgers
flushInterval=100
zkServers=z01.zookeeper.youja.cn:2181,z02.zookeeper.youja.cn:2181,z03.zookeeper.youja.cn:2181,z04.zookeeper.youja.cn:2181,z05.zookeeper.youja.cn
zkTimeout=10000
serverTcpNoDelay=true

三，启动

bookkeeper bookie

================================================================================

su hadoop 

# hadoop 
for host in secondary.hadoop.youja.cn master.hadoop.youja.cn slave01.hadoop.youja.cn slave02.hadoop.youja.cn slave03.hadoop.youja.cn
do
    echo "==> $host"
    #rsync -rtlv -e "ssh -p 50022" /usr/local/hadoop-2.2.0/ hadoop@$host:/usr/local/hadoop-2.2.0/
    ssh -p 50022 $host "rm -rf /usr/local/hadoop-2.2.0/logs/*"
    ssh -p 50022 $host "rm -rf /data/hdfs;mkdir -p /data/hdfs/{data,name,tmp}"
    
done
echo -e "\nIt's OK.\n"

hadoop namenode -format

zookeeper & bookkeeper 搭建并使用

chown chown -R hadoop.hadoop /usr/local/zookeeper-3.4.6 /usr/local/bookkeeper-server-4.2.3
mkdir -p /data/zookeeper/{data,log,bookkeeper} /usr/local/{bookkeeper-server-4.2.3,zookeeper-3.4.6}
chown -R hadoop.hadoop /data/zookeeper  /usr/local/{bookkeeper-server-4.2.3,zookeeper-3.4.6} /usr/local/jdk*

# zookeeper & bookkeeper
for i in {1..5}
do
    host="z0$i.zookeeper.youja.cn"
    echo "==> $host"
    #rsync -rtlv -e "ssh -p 50022" /usr/local/zookeeper-3.4.6/ hadoop@$host:/usr/local/zookeeper-3.4.6/
    #rsync -rtlv -e "ssh -p 50022" /usr/local/bookkeeper-server-4.2.3/ hadoop@$host:/usr/local/bookkeeper-server-4.2.3/
    
    #ssh -p 50022 $host "rm -rf /data/zookeeper;mkdir -p /data/zookeeper/{data,log,bookkeeper};echo \"$i\"> /data/zookeeper/data/myid"

    #ssh -p 50022 $host "/usr/local/zookeeper-3.4.6/bin/zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo.cfg"
    #ssh -p 50022 $host "rm -f ~/zookeeper.out;rm -f /data/zookeeper/data/zookeeper_server.pid"
    #ssh -p 50022 $host "/usr/local/zookeeper-3.4.6/bin/zkServer.sh start /usr/local/zookeeper-3.4.6/conf/zoo.cfg"

    ssh -p 50022 $host "bookkeeper bookie"
    
    ssh -p 50022 $host "ls -l ~"
    ssh -p 50022 $host "netstat -nutlp"
    ssh -p 50022 $host "tree /data/zookeeper"

done
echo -e "\nIt's OK.\n"


================================================================================
HBase 集群搭建及使用
================================================================================

一，下载及环境准备

cd /usr/local/src
wget -O hbase-0.96.2-hadoop2-bin.tar.gz http://file.uplus.youja.cn/hadoop/hbase/hbase-0.96.2-hadoop2-bin.tar.gz 
tar xvzf hbase-0.96.2-hadoop2-bin.tar.gz
mv hbase-0.96.2-hadoop2 /usr/local/
chown -R hadoop.hadoop /usr/local/hbase-0.96.2-hadoop2

vim /etc/profile.d/hadoop-env.sh

...

# env hbase
export HBASE_HOME=/usr/local/hbase-0.96.2-hadoop2
export PATH=$HBASE_HOME/bin:$PATH


二，修改配置

--单机启动--
mkdir -p /data/hadoop/hbase
chown -R hadoop.hadoop /data/hadoop

vim /usr/local/hbase-0.96.2-hadoop2/conf/hbase-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <!-- <value>/data/hadoop/hbase</value> -->
    <value>hdfs://master.hadoop.youja.cn:9000/hbase</value>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  
</configuration>

vim /usr/local/hbase-0.96.2-hadoop2/conf/regionservers
secondary.hadoop.youja.cn 
master.hadoop.youja.cn 
slave01.hadoop.youja.cn 
slave02.hadoop.youja.cn 
slave03.hadoop.youja.cn

--作为hdfs客户配置--
cd /usr/local/hbase-0.96.2-hadoop2/conf
ln -s ../../hadoop-2.2.0/etc/hadoop/hdfs-site.xml ./
在hbase-env.sh里将HBASE_CLASSPATH环境变量加上HADOOP_CONF_DIR

vim /usr/local/hbase-0.96.2-hadoop2/conf/hbase-env.sh
# Extra ssh options.  Empty by default.
export HBASE_SSH_OPTS="-p 50022 -o ConnectTimeout=1 -o SendEnv=HADOOP_CONF_DIR"

cp /usr/local/hbase-0.96.2-hadoop2/lib/*.jar /usr/local/hadoop-2.2.0/share/hadoop/common/lib/

三，启动

start-hbase.sh

四，测试使用

hbase shell
create 'test','cf'
put 'test','row1','cf:a','value1'
put 'test','row2','cf:b','value2'
put 'test','row3','cf:c','value3'
scan 'test'
get 'test','row1'
disable 'test'

http://master.hadoop.youja.cn:60010


# hbase 
for host in secondary.hadoop.youja.cn master.hadoop.youja.cn slave01.hadoop.youja.cn slave02.hadoop.youja.cn slave03.hadoop.youja.cn
do
    echo "==> $host"
    rsync -rtlv -e "ssh -p 50022" /usr/local/hbase-0.96.2-hadoop2/ hadoop@$host:/usr/local/hbase-0.96.2-hadoop2/
    ssh -p 50022 $host "rm -f /usr/local/hbase-0.96.2-hadoop2/logs/*"
    
done
echo -e "\nIt's OK.\n"







